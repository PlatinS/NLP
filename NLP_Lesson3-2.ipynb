{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Введение в обработку естественного языка. Урок 3. Создание признакового пространства."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('combine_df.pickle', 'rb') as f:\n",
    "    combine_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love yoyou take with yoyou all the time ...</td>\n",
       "      <td>[model, love, yoyou, take, with, yoyou, all, t...</td>\n",
       "      <td>[model, love, yoyou, take, yoyou, time, yoyour]</td>\n",
       "      <td>[model, love, yoyou, take, yoyou, time, yoyour]</td>\n",
       "      <td>[model, love, yoyou, take, yoyou, time, yoyour]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when father is dysfunctional and is so selfish...   \n",
       "1  thanks for lyft credit cannot use cause they d...   \n",
       "2                                bihday your majesty   \n",
       "3  model love yoyou take with yoyou all the time ...   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, yoyou, take, with, yoyou, all, t...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3    [model, love, yoyou, take, yoyou, time, yoyour]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                  [bihday, majesti]   \n",
       "3    [model, love, yoyou, take, yoyou, time, yoyour]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...  \n",
       "2                                  [bihday, majesty]  \n",
       "3    [model, love, yoyou, take, yoyou, time, yoyour]  \n",
       "4                  [factsguide, society, motivation]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.max_length = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 52s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wheelchair vans</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pdx</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tomorrow</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the next school year</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   text     ner\n",
       "0       wheelchair vans     ORG\n",
       "1                   pdx     ORG\n",
       "2                bihday  PERSON\n",
       "3              tomorrow    DATE\n",
       "4  the next school year    DATE"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "combine_df['NER'] = combine_df['clean_tweet'].apply(lambda x:  nlp(x))\n",
    "ner = combine_df['NER'].tolist()\n",
    "\n",
    "NER = []\n",
    "for doc in ner:\n",
    "    for ent in doc.ents:\n",
    "        NER.append((ent.text, ent.label_))\n",
    "\n",
    "df_ner = pd.DataFrame(NER, columns=['text', 'ner'])\n",
    "df_ner.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE           11502\n",
       "PERSON          8039\n",
       "ORG             5572\n",
       "GPE             4571\n",
       "TIME            2021\n",
       "NORP            1450\n",
       "CARDINAL        1098\n",
       "ORDINAL          647\n",
       "FAC              304\n",
       "LOC              216\n",
       "EVENT            150\n",
       "PRODUCT           63\n",
       "LANGUAGE          43\n",
       "QUANTITY          34\n",
       "WORK_OF_ART       27\n",
       "LAW               21\n",
       "MONEY              8\n",
       "PERCENT            3\n",
       "Name: ner, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ТОП-20 популярных NER\n",
    "top_20_ner = df_ner.ner.value_counts().head(20)\n",
    "top_20_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hea                                                        117\n",
       "hu                                                          83\n",
       "blur sun                                                    54\n",
       "bihday                                                      46\n",
       "feminismiscancer feminismisterrorism feminismmuktbharat     40\n",
       "christina grimmie                                           38\n",
       "hillary                                                     36\n",
       "sikh temple                                                 28\n",
       "tgif ff                                                     26\n",
       "don                                                         24\n",
       "detoxdiet altwaystoheal                                     21\n",
       "clinton                                                     21\n",
       "ripchristina                                                20\n",
       "jo cox                                                      20\n",
       "carl paladino                                               19\n",
       "regrann                                                     17\n",
       "karen iqbal                                                 17\n",
       "donald trump                                                16\n",
       "moon                                                        15\n",
       "anton yelchin                                               15\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # ТОП-20 популярных персон\n",
    "top_20_pers = df_ner.loc[df_ner['ner'] == 'PERSON']\n",
    "top_20_pers = top_20_pers.text.value_counts().head(20)\n",
    "top_20_pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bong bing           107\n",
       "app                  84\n",
       "gop                  77\n",
       "islam                58\n",
       "house                47\n",
       "social analytics     40\n",
       "nba                  39\n",
       "usa                  34\n",
       "amazon               32\n",
       "sta                  31\n",
       "sma                  30\n",
       "cnn                  28\n",
       "euro                 26\n",
       "fed                  25\n",
       "ios                  23\n",
       "eu                   22\n",
       "fbi                  21\n",
       "sun                  20\n",
       "bogota colombia      20\n",
       "congress             19\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # ТОП-20 популярных организаций\n",
    "top_20_org = df_ner.loc[df_ner['ner'] == 'ORG']\n",
    "top_20_org = top_20_org.text.value_counts().head(20)\n",
    "top_20_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\samia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\samia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_nltk = {\n",
    "    \"text\": [],\n",
    "    \"label\": [],\n",
    "}\n",
    "\n",
    "def nltk_ner(tweet):\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(tweet.title()))):\n",
    "         if hasattr(chunk, 'label'):\n",
    "            ner_nltk['text'].append(' '.join(c[0] for c in chunk))\n",
    "            ner_nltk['label'].append(chunk.label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "49154    None\n",
       "49155    None\n",
       "49156    None\n",
       "49157    None\n",
       "49158    None\n",
       "Name: clean_tweet, Length: 49159, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['clean_tweet'].apply(lambda x: nltk_ner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Father</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kids</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lyft Credit</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Offer Wheelchair</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pdx</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text         label\n",
       "0            Father        PERSON\n",
       "1              Kids  ORGANIZATION\n",
       "2       Lyft Credit        PERSON\n",
       "3  Offer Wheelchair        PERSON\n",
       "4               Pdx           GPE"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df_ntlk = pd.DataFrame.from_dict(ner_nltk)\n",
    "ner_df_ntlk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Happy                         1113\n",
       "New                            528\n",
       "Yoyour                         501\n",
       "Model                          500\n",
       "Love Yoyou Take With Yoyou     497\n",
       "Father                         494\n",
       "Good                           421\n",
       "Love                           367\n",
       "Will                           347\n",
       "Great                          272\n",
       "Us                             262\n",
       "Bull Up                        246\n",
       "Orlando                        239\n",
       "Life                           205\n",
       "Ready                          191\n",
       "Sad                            191\n",
       "Forward                        167\n",
       "Have                           165\n",
       "Gorilla Simulator              162\n",
       "Got                            147\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df_ntlk.text.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Love Yoyou Take With Yoyou                497\n",
       "Well Deletetweets                         126\n",
       "Development Organizations Work Mindset     95\n",
       "Vicinity Of Their                          89\n",
       "Fathers                                    79\n",
       "Vast Expanse Of Mountains                  76\n",
       "Lot                                        68\n",
       "House                                      67\n",
       "Work Conference                            65\n",
       "Happiness                                  61\n",
       "City Each Side                             54\n",
       "Same                                       53\n",
       "All                                        52\n",
       "Melancholy Melancholymusic                 46\n",
       "Love                                       43\n",
       "Hate                                       37\n",
       "Weekend                                    37\n",
       "Into                                       37\n",
       "No                                         36\n",
       "Best                                       35\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df_ntlk.loc[ner_df_ntlk['label'] == 'ORGANIZATION'].text.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Happy                       995\n",
       "Model                       498\n",
       "Father                      481\n",
       "Will                        345\n",
       "Good                        313\n",
       "Love                        255\n",
       "Bull Up                     246\n",
       "Sad                         169\n",
       "Forward                     165\n",
       "Gorilla Simulator           162\n",
       "Have                        159\n",
       "Found Way How               130\n",
       "Delete Old                  130\n",
       "Ready                       127\n",
       "Trump                       118\n",
       "Attack Bull                 115\n",
       "Aww                         115\n",
       "Help                        112\n",
       "Good Bing Bong Bing Bong    107\n",
       "Hey                         107\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df_ntlk.loc[ner_df_ntlk['label'] == 'PERSON'].text.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Библиотека Spacy отработала лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
